#-------------------------------------------------------------------------
# AUTHOR: Alexander Rodriguez 
# FILENAME: bagging_random_forest.py 
# SPECIFICATION: description of the program
# FOR: CS 4210- Assignment #4
# TIME SPENT: 45min - 1hr 
#-----------------------------------------------------------*/

#IMPORTANT NOTE: DO NOT USE ANY ADVANCED PYTHON LIBRARY TO COMPLETE THIS CODE SUCH AS numpy OR pandas. You have to work here only with standard vectors and arrays

#importing some Python libraries
from sklearn import tree
from sklearn.utils import resample
from sklearn.ensemble import RandomForestClassifier

dbTraining = []
dbTest = []
X_training = []
y_training = []
classVotes = [] #this array will be used to count the votes of each classifier

#reading the training data from a csv file and populate dbTraining
with open('optdigits.tra', 'r') as f:
    for line in f.readlines():
        line = line.strip().split(',')
        line = [int(x) for x in line]
        dbTraining.append(line)

#reading the test data from a csv file and populate dbTest
with open('optdigits.tes', 'r') as f:
    for line in f.readlines():
        line = line.strip().split(',')
        line = [int(x) for x in line]
        dbTest.append(line)

#inititalizing the class votes for each test sample.
for i in range(len(dbTest)):
    classVotes.append([0]*10)

print("Started my base and ensemble classifier ...")

accuracy = 0
for k in range(20): #we will create 20 bootstrap samples here (k = 20). One classifier will be created for each bootstrap sample

    bootstrapSample = resample(dbTraining, n_samples=len(dbTraining), replace=True)

    #populate the values of X_training and y_training by using the bootstrapSample
    X_training = [sample[:-1] for sample in bootstrapSample]
    y_training = [sample[-1] for sample in bootstrapSample]

    #fitting the decision tree to the data
    clf = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth=None) #we will use a single decision tree without pruning it
    clf = clf.fit(X_training, y_training)

    for i, testSample in enumerate(dbTest):

        #make the classifier prediction for each test sample and update the corresponding index value in classVotes.
        class_predicted = clf.predict([testSample[:-1]])
        classVotes[i][class_predicted[0]] += 1

        if k == 0: #for only the first base classifier, compare the prediction with the true label of the test sample here to start calculating its accuracy
            if class_predicted[0] == testSample[-1]:
                accuracy += 1

    if k == 0: #for only the first base classifier, print its accuracy here
        accuracy = accuracy/len(dbTest)*100
        print("Finished my base classifier (fast but relatively low accuracy) ...")
        print("My base classifier accuracy: " + str(accuracy) + "%")
        print("")

#now, compare the final ensemble prediction (majority vote in classVotes) for each test sample with the ground truth label to calculate the accuracy of the ensemble classifier (all base classifiers together)

# Define a function to find the index of the maximum value in an array
def argmax(arr):
    max_val = arr[0]
    max_idx = 0
    for i in range(len(arr)):
        if arr[i] > max_val:
            max_val = arr[i]
            max_idx = i
    return max_idx

ensemble_accuracy = 0
for i, testSample in enumerate(dbTest):
    ensemble_class_predicted = argmax(classVotes[i])
    if ensemble_class_predicted == testSample[-1]:
        ensemble_accuracy += 1

ensemble_accuracy = ensemble_accuracy/len(dbTest)*100

#printing the ensemble accuracy here
print("Finished my ensemble classifier (slow but higher accuracy) ...")
print("My ensemble accuracy: " + str(ensemble_accuracy) + "%")
print("")

print("Started Random Forest algorithm ...")

#Create a Random Forest Classifier
clf=RandomForestClassifier(n_estimators=20) #this is the number of decision trees that will be generated by Random Forest. The sample of the ensemble method used before

#Fit Random Forest to the training data
clf.fit(X_training,y_training)

#make the Random Forest prediction for each test sample. Example: class_predicted_rf = clf.predict([[3, 1, 2, 1, ...]]
class_predicted_rf = clf.predict([row[:-1] for row in dbTest])

#compare the Random Forest prediction for each test sample with the ground truth label to calculate its accuracy
accuracy_rf = 0
for i in range(len(dbTest)):
    if class_predicted_rf[i] == dbTest[i][-1]:
        accuracy_rf += 1
accuracy_rf /= len(dbTest)

#printing Random Forest accuracy here
print("Random Forest accuracy: " + str(accuracy_rf))

print("Finished Random Forest algorithm (much faster and higher accuracy!) ...")
